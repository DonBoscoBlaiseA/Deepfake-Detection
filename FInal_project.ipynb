{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuyFtF460Y99"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.metrics import AUC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_path = 'datasets/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n",
        "second_main_path = 'datasets/deepfake-and-real-images/Dataset'\n",
        "\n",
        "def create_dataframe(base_path, sub_dir, label_map):\n",
        "    data = {\"file_path\": [], \"label\": []}\n",
        "    for label_dir, label in label_map.items():\n",
        "        folder_path = os.path.join(base_path, sub_dir, label_dir)\n",
        "        if os.path.exists(folder_path):\n",
        "            for img_file in os.listdir(folder_path):\n",
        "                data[\"file_path\"].append(os.path.join(folder_path, img_file))\n",
        "                data[\"label\"].append(label)\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "label_mapping = {'real': 1, 'fake': 0, 'Real': 1, 'Fake': 0}\n",
        "sub_dirs_mapping = {'train': ['train', 'Train'], 'test': ['test', 'Test'], 'valid': ['valid', 'Validation']}\n"
      ],
      "metadata": {
        "id": "kCUdu94m0kFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sub_dir_key, sub_dirs in sub_dirs_mapping.items():\n",
        "    combined_data = pd.DataFrame()\n",
        "    for base_path, sub_dir in [(main_path, sub_dirs[0]), (second_main_path, sub_dirs[1])]:\n",
        "        df = create_dataframe(base_path, sub_dir, label_mapping)\n",
        "        combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
        "    csv_path = f\"{sub_dir_key}.csv\"\n",
        "    combined_data.to_csv(csv_path, index=False)\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "valid_df = pd.read_csv(\"valid.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_df = pd.read_csv(\"test.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "train_df['label'] = train_df['label'].astype(str)\n",
        "valid_df['label'] = valid_df['label'].astype(str)\n",
        "test_df['label'] = test_df['label'].astype(str)"
      ],
      "metadata": {
        "id": "9LZxreKL0nHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (256, 256)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True)\n",
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='file_path',\n",
        "    y_col='label',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "valid_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=valid_df,\n",
        "    x_col='file_path',\n",
        "    y_col='label',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='file_path',\n",
        "    y_col='label',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "uvW6y8gv0pV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "with strategy.scope():\n",
        "    base_model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3))\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", AUC(name='auc')])\n",
        "\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "checkpoint_path = \"Combined_best_model.keras\"\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    checkpoint_path,\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    mode=\"max\",\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=11,\n",
        "    callbacks=[model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "etvjcRkM0r6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "test_loss, test_accuracy, test_auc = model.evaluate(test_generator)\n",
        "\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test AUC: {test_auc:.2f}\")"
      ],
      "metadata": {
        "id": "_9ALU97Y0vW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}